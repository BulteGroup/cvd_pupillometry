# -*- coding: utf-8 -*-
'''
Created on Mon Mar 30 17:05:47 2020
@author: JTM
note: credit to Acland BT, Braver TS (2014) for some of this code
https://github.com/beOn/cili
Acland BT, Braver TS (2014). Cili (v0.5.4) [Software] 
Available from http://doi.org/10.5281/zenodo.48843. doi:10.5281/zenodo.48843
'''

import os
import shutil
import os.path as op
from copy import deepcopy

import numpy as np
import pandas as pd
import scipy.interpolate as spi

##########################
# FUNCTIONS TO LOAD DATA #
##########################

class Subject():    
    def __init__(self, subjdir, export='000', out_dir_nm='pyplr_analysis'):
        '''
        Get a handle on a subject for data analysis.
        
        Parameters
        ----------
        subjdir : str
            Full path to a Pupil Labs recording directory for a given subject.
        export : str
            The export folder in which to look for files (in case of multiple 
            exports). The default is '000'.
        out_dir_nm : str, optional
            Name for the folder where output will be saved. The default is
            'pyplr_analysis'.

        Raises
        ------
        FileNotFoundError
            If subjdir does not exist.

        Returns
        -------
        None.

        '''
        self.root = subjdir
        self.export = export
        self.out_dir_nm = out_dir_nm
        self.id = op.basename(self.root)
        self.pl_data_dir = op.join(self.root, 'exports', '', self.export, '')
        self.out_dir = op.join(self.root, self.out_dir_nm, '')
        if not op.isdir(self.root):
            raise FileNotFoundError(
                '"{}" does not appear to exist.'.format(self.root))
        if os.path.exists(self.out_dir):
            shutil.rmtree(self.out_dir)
        os.mkdir(self.out_dir)
        print('{}\n{:*^60s}\n{}'.format('*'*60, ' ' + self.id + ' ', '*'*60))

    def print_file_structure(self):
        '''
        Print the file structure of the recording directory.

        Returns
        -------
        None.

        '''
        for root, dirs, files in os.walk(self.root):
            level = root.replace(self.root, '').count(os.sep)
            indent = ' ' * 4 * (level)
            print(f'{indent}{os.path.basename(root)}/')
            subindent = ' ' * 4 * (level + 1)
            for f in sorted(files):
                print(f'{subindent}{f}')

def load_annotations(data_dir):
    '''
    Loads annotations (a.k.a. 'triggers', 'events', etc.) exported 
    from Pupil Player.
    
    Parameters
    ----------
    data_dir : str
        Directory where the Pupil Labs 'annotations' data exists.
        
    Returns
    -------
    events : DataFrame
        Pandas DataFrame containing events.
        
    '''
    fname = op.join(data_dir, '', 'annotations.csv')
    try:
        events = pd.read_csv(fname)
        print('Loaded {} events'.format(len(events)))
        return events
    except FileNotFoundError:
        print('{} does not appear to exist. Make sure annotations plugin is \
              active before exporting'.format(fname))
    
   
def load_pupil(data_dir, eye=None, method='3d c++', cols=None):
    '''
    Loads 'pupil_positions' data exported from Pupil Player.
    
    Parameters
    ----------
    data_dir : str
        Directory where the Pupil Labs 'annotations' data exists.
    eye : str
        Eye to load. Must be 'left', 'right' or 'both'. If 'both', the binocular 
        data is returned in a single DataFrame containing binocular data with 
        the right eye joined to the nearest timestamp of the left eye. In most
        cases it will be preferable to load each eye separately. The 
        default is None.
    method : string, optional
        Whether to load pupil data generated by the 2d or 3d fitting method. 
        The default is '3d c++'.
    cols : list, optional
        Columns to load from the file, e.g. ['pupil_timestamp','diameter',
        'diameter_3d'] (check file for options). The default is None 
        (loads all columns).
        
    Returns
    -------
    samps : DataFrame
        Pandas DataFrame containing requested samples.
        
    '''
    fname = op.join(data_dir, '', 'pupil_positions.csv')
    try:
        if cols is None:
            samps = pd.read_csv(fname)
        else:
            default_cols = ['pupil_timestamp', 'eye_id', 'method']
            cols = list(set(default_cols + cols))
            samps = pd.read_csv(fname, usecols=cols)
        samps.set_index('pupil_timestamp', inplace=True)
        samps = samps[samps.method==method]  
        if eye == 'left':
            samps = samps[samps.eye_id==1]
        elif eye == 'right':
            samps = samps[samps.eye_id==0]
        #TODO: verify this approach
        elif eye == 'both':     
            eye_left  = samps[samps.eye_id==1]
            eye_right = samps[samps.eye_id==0]
            samps = pd.merge_asof(
                eye_left, eye_right, left_index=True, 
                right_index=True, suffixes=('_1','_0'))
            keep = [col for col in samps.columns if col not in \
                 ['eye_id_1','eye_id_0', 'method_1', 'method_0']]
            samps = samps[keep]
            samps['method'] = method
            samps['eye_id'] = 'both'
        else:
            raise ValueError('Eye must be left, right or both.')
        return samps
    except FileNotFoundError:
        print('{} does not appear to exist. Check directory and pupil \
              player'.format(fname))

def load_blinks(data_dir):
    '''
    Loads 'blinks' data exported from Pupil Player.
    
    Parameters
    ----------
    data_dir : str
        Directory where the Pupil Labs 'blinks' data exists.
    Returns
    -------
    blinks : DataFrame
        Pandas DataFrame containing blink events.
        
    '''
    fname = op.join(data_dir, '', 'blinks.csv')
    try:
        blinks = pd.read_csv(fname)
        print('{} blinks detected by Pupil Labs (mean dur = {:.3f} s)'.format(
            len(blinks), blinks.duration.mean()))
        return blinks
    except FileNotFoundError:
        print('{} does not appear to exist. Make sure blink detection plugin \
              is active before exporting in Pupil Player'.format(fname))

###########################
# FUNCTIONS TO CLEAN DATA #
###########################

def even_samples(samps, sample_rate, fields=['diameter']):
    '''
    Resample the data in fields to a new index with evenly spaced timepoints
    starting from 0 in steps of 1 / sample_rate.

    Parameters
    ----------
    samps : TYPE
        DESCRIPTION.
    sample_rate : TYPE
        DESCRIPTION.
    fields : TYPE, optional
        DESCRIPTION. The default is ['diameter'].

    Returns
    -------
    samps : TYPE
        DESCRIPTION.

    '''
    # TODO: When is the best time to do this?
    x = samps.index.to_numpy()
    x = x - x[0]
    xnew = np.arange(0, len(samps)) * (1/sample_rate)
    for f in fields:
        y = samps[f].to_numpy()
        func = spi.interp1d(x, y)
        samps[f] = func(xnew)
    samps.index = xnew
    return samps

def even_samples(rangs, sample_rate, fields=[]):
    for idx, df in rangs.groupby(level=['event']):
        for f in fields:
            x = df.orig_idx.to_numpy()
            x = x - x[0]
            xnew = np.arange(0, len(df)) * (1/sample_rate)
            y = df.loc[idx, f]
            func = spi.interp1d(x, y)
            rangs.loc[idx, f] = func(xnew)
            rangs.loc[idx, 'even_onset'] = xnew
    rangs = rangs.reset_index().set_index(['event','even_onset'])
    return rangs

def mask_pupil_first_derivative(samples, 
                                threshold=3.0,
                                mask_cols=['diameter']):
    '''
    Use a statistical criterion on the first derivative of pupil data to mask 
    poor quality data. Helpful for dealing with blinks. 

    Parameters
    ----------
    samples : DataFrame
        Samples containing the data to be masked.
    threshold : float, optional
        Number of standard deviations from the mean of the first derivative 
        to use as the threshold for masking. The default is 3.0.
    mask_cols : list, optional
        Columns to mask. The default is ['diameter'].

    Returns
    -------
    samps : DataFrame
        masked data

    '''
    samps = samples.copy(deep=True)
    for col in mask_cols:
        d = samples[col].diff()
        m = samples[col].diff().mean()
        s = samples[col].diff().std() * threshold
        #TODO: check this works properly
        samps[col] = samps[col].mask((d < (m-s)) | (d > (m+s)))
        samps[samps[col] == 0] = np.nan
    return samps

def mask_pupil_confidence(samples, threshold=.8, mask_cols=['diameter']):
    '''
    Sets data in mask_cols to NaN where the corresponding confidence metric is
    below threshold. Pupil Labs reccommend a threshold of 0.8. Helpful for
    dealing with blinks. 

    Parameters
    ----------
    samples : DataFrame
        Samples containing the data to be masked.
    threshold : float, optional
        Confidence threshold for masking. The default is 0.8.
    mask_cols : list, optional
        Columns to mask. The default is ['diameter'].

    Returns
    -------
    samps : DataFrame
        masked data

    '''
    samps = samples.copy(deep=True)
    samps[mask_cols] = samps[mask_cols].mask(samps.confidence < threshold)
    return samps

def interpolate_pupil(samples, interp_cols=['diameter']):
    '''
    Use linear interpolation to reconstruct nan values in interp_cols.

    Parameters
    ----------
    samples : DataFrame
        Samples containing the data to be interpolated.
    interp_cols : list, optional
        Columns to interpolate. The default is ['diameter'].

    Returns
    -------
    samps : DataFrame
        masked data

    '''
    samps = samples.copy(deep=True)
    samps['interpolated'] = 0
    samps.loc[samps[interp_cols].isna().any(axis=1), 'interpolated'] = 1
    samps[interp_cols] = samps[interp_cols].interpolate(
        method='linear', axis=0, inplace=False)
    return samps
    
def pupil_confidence_filter(samples, threshold=.8, mask_cols=['diameter']):
    '''
    Sets data in mask_cols to NaN where the corresponding confidence metric is
    below threshold. Pupil Labs reccommend a threshold of .8. An alterntive
    to interpolating blinks. 

    Parameters
    ----------
    samples : DataFrame
        The samples from which to pull indices.
    threshold : float, optional
        Threshold to use for filtering by confidence. The default is .8.
    mask_cols : list, optional
        Columns to mask. The default is ['diameter'].

    Returns
    -------
    samps : DataFrame
        masked data
        
    '''
    
    samps = samples.copy(deep=True)
    indices = samples[samples.confidence<threshold].index
    samps.loc[indices, mask_cols] = float('nan')
    samps['interpolated'] = 0
    samps.loc[indices, 'interpolated'] = 1
    return samps
    
# def pupil_first_derivative_filter(samples, threshold=.8, pupil_col=['diameter']):
#     samps = samples.copy(deep=True)
#     samps
#     return samps

def ev_row_idxs(samples, blinks):
    ''' 
    Returns the indices in 'samples' contained in events from 'events'.
    
    Parameters
    ----------
    samples : DataFrame
        The samples from which to pull indices.
    events : DataFrame
        The events whose indices should be pulled from 'samples'.
        
    Returns
    -------
    samps : DataFrame
        masked data
        
    '''
    idxs = []
    for start, end in zip(blinks['start_timestamp'], blinks['end_timestamp']):
        idxs.extend(list(samples.loc[start:end].index))
    idxs = np.unique(idxs)
    idxs = np.intersect1d(idxs, samples.index.tolist())
    return idxs

def get_mask_idxs(samples, blinks):
    '''
    Finds indices from 'samples' within the returned events.
    
    '''
    blidxs = ev_row_idxs(samples, blinks)
    return blidxs

def mask_blinks(samples, blinks, mask_cols=['diameter']):
    '''
    Sets untrustworthy pupil data to NaN.
    
    Parameters
    ----------
    samples : DataFrame
        Must contain at least 'pupil_timestamp' and 'diameter' columns
    blinks : DataFrame
        Must contain 'start_timestamp' and 'end_timestamp' columns
    mask_cols : list, optional
        Columns to mask. The default is ['diameter'].
    Returns
    -------
    samps : DataFrame
        masked data
        
    '''
    samps = samples.copy(deep=True)
    indices = get_mask_idxs(samps, blinks)
    samps.loc[indices, mask_cols] = float('nan')
    samps['interpolated'] = 0
    samps.loc[indices, 'interpolated'] = 1
    return samps

def interpolate_blinks(samples, blinks, fields=['diameter']):
    '''
    Reconstructs Pupil Labs eye blinks with linear interpolation.
    
    Parameters
    ----------
    samples : DataFrame
        Must contain at least 'pupil_timestamp' and 'diameter' columns
    blinks : DataFrame
        Must contain 'start_timestamp' and 'end_timestamp' columns
    interp_cols : list, optional
        Columns to interpolate. The default is ['diameter'].
        
    Returns
    -------
    samps : DataFrame
        blink-interpolated data
        
    '''
    #TODO: fix this pipeline
    samps = mask_blinks(samples, blinks, mask_cols=fields)
    n = samps[fields].isna().sum().max()
    samps = samps.interpolate(method='linear', axis=0, inplace=False)
    #breakpoint()
    print('{} samples ({:.3f} %) reconstructed with linear interpolation'.format(
        len(samps.loc[samps['interpolated']==1]), n))
    return samps

def mask_zeros(samples, mask_cols=['diameter']):
    ''' 
    Sets any 0 values in columns in mask_cols to NaN.
    
    Parameters
    ----------
    samples : DataFrame
        The samples to search for 0 values.
    mask_fields (list of strings)
        The columns to search for 0 values.
        
    '''
    samps = samples.copy(deep=True)
    for f in mask_cols:
        samps[samps[f] == 0] = float('nan')
    return samps

def interpolate_zeros(samples, fields=['diameter']):
    ''' 
    Replace 0s in "samples" with linearly interpolated data.
    Parameters
    ----------
    samples : DataFrame
        The samples in which you'd like to replace 0s
    interp_cols : list
        The column names from samples in which you'd like to replace 0s.
    '''
    samps = mask_zeros(samples, mask_cols=fields)
    samps = samps.interpolate(method='linear', axis=0, inplace=False)
    # since interpolate doesn't handle the start/finish, bfill the ffill to
    # take care of NaN's at the start/finish samps.
    samps.fillna(method='bfill', inplace=True)
    samps.fillna(method='ffill', inplace=True)
    return samps  

def butterworth_series(samples,
                       fields=['diameter'], 
                       filt_order=3,
                       cutoff_freq=.01,
                       inplace=False):
    '''
    Applies a butterworth filter to the given fields
    See documentation on scipy's butter method FMI.
    
    The cutoff freq should be 4/(sample_rate/2)
    '''
    import scipy.signal as signal
    samps = samples if inplace else samples.copy(deep=True)
    B, A = signal.butter(filt_order, cutoff_freq, output='BA')
    samps[fields] = samps[fields].apply(
        lambda x: signal.filtfilt(B, A, x), axis=0)
    return samps

def savgol_series(samples, 
                  fields=['diameter'], 
                  window_length=51, 
                  filt_order=7,
                  inplace=False): 
    '''
    Applies a savitsky-golay filter to the given fields
    See documentation on scipys savgol_filter method FMI.
    '''
    import scipy.signal as signal
    samps = samples if inplace else samples.copy(deep=True)
    samps[fields] = samps[fields].apply(
        lambda x: signal.savgol_filter(x, window_length, filt_order), axis=0)
    return samps
    
###########
# extract #
###########
    
def extract(samples, 
            events, 
            offset=0, 
            duration=0,
            borrow_attributes=[]):
    '''
    Extracts ranges from samples based on event timing and sample count.
    
    Parameters
    ----------
    samples : DataFrame
        The samples from which to extract events. Index must be timestamp.
    events : DataFrame
        The events to extract. Index must be timestamp.
    offset : int, optional
        Number of samples to offset from baseline. The default is 0.
    duration : int, optional
        Duration of all events in terms of the number of samples. Currently 
        this has to be the same for all events, but could use a 'duration' 
        column in events DataFrame if needs be. The default is 0.
    borrow_attributes : list of str, optional
        List of column names in the events DataFrame whose values should be
        copied to the respective ranges. For each item in the list, a
        column will be created in the ranges dataframe - if the column does
        not exist in the events dataframe, the values in the each
        corresponding range will be set to float('nan'). This is uesful for 
        marking conditions, grouping variables, etc. The default is [].
        
    Returns
    -------
    df : DataFrame
        Extracted events complete with hierarchical multi-index.
        
    '''
    # negative duration should raise an exception
    if duration <= 0:
        raise ValueError('Duration must be >0')
        
    # get the list of start time indices
    event_starts = events.index.to_series()

    # find the indexes of the event starts, and offset by sample count
    range_idxs = np.searchsorted(
        samples.index, event_starts.iloc[:], 'left') + offset
    range_duration = duration
    
    # make a hierarchical index
    samples['orig_idx'] = samples.index
    midx = pd.MultiIndex.from_product(
        [list(range(len(event_starts))), list(range(range_duration))],
        names=['event', 'onset'])
    
    # get the samples
    df = pd.DataFrame()
    idx = 0
    for start_idx in range_idxs:
        # get the start time and add the required number of indices
        end_idx = start_idx + range_duration - 1  # pandas.loc indexing is inclusive
        print(end_idx-start_idx)
        # deepcopy for old bugs
        new_df = deepcopy(
            samples.loc[samples.index[start_idx] : samples.index[end_idx]])
        new_df = new_df.iloc[0:range_duration]
        assert len(new_df) == range_duration, 'Extracted range is biger than expected'
        for ba in borrow_attributes:
            new_df[ba] = events.iloc[idx].get(ba, float('nan'))
        df = pd.concat([df, new_df])
        idx += 1
    df.index = midx
    
    print('Extracted ranges for {} events'.format(len(events)))
    return df

def reject_bad_trials(ranges, interp_thresh=20, drop=False):
    '''
    Drop or markup trials which exceed a threshold of interpolated data.
    
    Parameters
    ----------
    ranges : DataFrame
        Extracted event ranges with hierarchical pd.MultiIndex.
    interp_thresh : int, optional
        Percentage of interpolated data permitted before trials are marked for
        rejection / dropped. The default is 20.
    drop : bool, optional
        Whether to drop the trials from the ranges. The default is False.
        
    Returns
    -------
    ranges : DataFrame
        Same as ranges but with a column identifying trials marked for
        rejection (drop = False) or with those trials dropped from the 
        DataFrame (drop = True).
        
    '''
    if not isinstance(ranges.index, pd.MultiIndex):
        raise ValueError('Index of ranges must be pd.MultiIndex')
        
    pct_interp = ranges.groupby(by='event').agg(
        {'interpolated':lambda x: float(x.sum())/len(x)*100})
    print('Percentage of data interpolated for each trial (mean = {:.2f}): \n'.format(
        pct_interp.mean()[0]), pct_interp)
    reject_idxs = (pct_interp.loc[pct_interp['interpolated'] > interp_thresh]
                             .index.to_list())
    ranges['reject'] = 0
    if reject_idxs:
        ranges.loc[reject_idxs, 'reject'] = 1
    if drop:
        ranges = ranges.drop(index=reject_idxs)
        print('{} trials were dropped from the DataFrame'.format(
            len(reject_idxs)))
    else:
        print('{} trials were marked for rejection'.format(len(reject_idxs)))
    return ranges
