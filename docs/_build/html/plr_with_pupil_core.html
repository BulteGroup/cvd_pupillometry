
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Measuring the pupillary light reflex with a Pupil Core headset &#8212; PyPlr v1.0 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Introduction to the STLAB light engine" href="STLAB_introduction.html" />
    <link rel="prev" title="Overview" href="overview.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Measuring-the-pupillary-light-reflex-with-a-Pupil-Core-headset">
<h1><strong>Measuring the pupillary light reflex with a Pupil Core headset</strong><a class="headerlink" href="#Measuring-the-pupillary-light-reflex-with-a-Pupil-Core-headset" title="Permalink to this headline">¶</a></h1>
<p>This notebook explores some functionality of the Pupil Core system and shows how, in principle, we can use it to measure the pupil’s light reflex and get accurate time-critical measures (e.g. latency to constrict, time-to-peak constriction) using the World Camera to detect light onset. To accomplish this we will need to make use of the Pupil Labs Network API, which uses <strong>ZeroMQ</strong> and <strong>MessagePack</strong> for fast and reliable communication. ZeroMQ (<a class="reference external" href="https://zeromq.org/">https://zeromq.org/</a>) is an open source universal
messaging library and MessagePack (<a class="reference external" href="https://msgpack.org/index.html">https://msgpack.org/index.html</a>) is a binary format for computer data interchange, like JSON but faster and more efficient.</p>
<p>To begin, make sure the tracker is plugged in and start the <strong>Pupil Capture</strong> real time application (download the latest version here: <a class="reference external" href="https://docs.pupil-labs.com/core/">https://docs.pupil-labs.com/core/</a>). Now we can can import zmq and and set up the Pupil Remote helper, which uses ZeroMQs REQ-REP (request-reply) pattern for reliable one-to-one communication. Pupil Remote accepts requests via a REP socket, which by default is on port 50020 (use the –port application argument to provide a custom port).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span><span class="p">,</span> <span class="n">time</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">msgpack</span>
<span class="kn">import</span> <span class="nn">zmq</span>

<span class="c1"># set up zmq context and remote helper for tracker</span>
<span class="n">context</span> <span class="o">=</span> <span class="n">zmq</span><span class="o">.</span><span class="n">Context</span><span class="p">()</span>
<span class="n">address</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>  <span class="c1"># remote ip or localhost</span>
<span class="n">request_port</span> <span class="o">=</span> <span class="s2">&quot;50020&quot;</span>  <span class="c1"># same as in the pupil remote gui</span>
<span class="n">pupil_remote</span> <span class="o">=</span> <span class="n">zmq</span><span class="o">.</span><span class="n">Socket</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">zmq</span><span class="o">.</span><span class="n">REQ</span><span class="p">)</span>
<span class="n">pupil_remote</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;tcp://</span><span class="si">{}</span><span class="s2">:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">address</span><span class="p">,</span> <span class="n">request_port</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>With Pupil Remote we can issue the following basic commands:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;R&#39;</span> <span class="c1"># start recording with auto generated session name</span>
<span class="s1">&#39;R rec_name&#39;</span> <span class="c1"># start recording named &quot;rec_name&quot;</span>
<span class="s1">&#39;r&#39;</span> <span class="c1"># stop recording</span>
<span class="s1">&#39;C&#39;</span> <span class="c1"># start currently selected calibration</span>
<span class="s1">&#39;c&#39;</span> <span class="c1"># stop currently selected calibration</span>
<span class="s1">&#39;T 1234.56&#39;</span> <span class="c1"># resets current Pupil time to given timestamp</span>
<span class="s1">&#39;t&#39;</span> <span class="c1"># get current Pupil time; returns a float as string.</span>
<span class="s1">&#39;v&#39;</span> <span class="c1"># get the Pupil Core software version string</span>
<span class="s1">&#39;PUB_PORT&#39;</span> <span class="c1"># return the current pub port of the IPC Backbone</span>
<span class="s1">&#39;SUB_PORT&#39;</span> <span class="c1"># return the current sub port of the IPC Backbone</span>
</pre></div>
</div>
<p>For example, the following code would start a recording, perform a calibration, wait for 40 seconds, and then stop the recording.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s1">&#39;R our_recording&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">())</span>

<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">())</span>

<span class="n">sleep</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>

<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
OK
OK
OK
</pre></div></div>
</div>
<p>Note that we need to receive the response for every command we send to Pupil Remote, otherwise Pupil Capture may become unresponsive. The recording just made will now be saved in the folder specified in Pupil Capture (Recorder&gt;&gt;Path to recordings), in a subfolder named ‘our_recording’ (use a leading / to start a new path from root). To view the recording, just launch <strong>Pupil Player</strong> and drop in the folder. For a script demonstrating a more complete interaction with Pupil Remote, see here:
<a class="reference external" href="https://github.com/pupil-labs/pupil-helpers/blob/master/python/pupil_remote_control.py">https://github.com/pupil-labs/pupil-helpers/blob/master/python/pupil_remote_control.py</a></p>
<div class="section" id="Accessing-data-in-real-time-with-the-IPC-Backbone">
<h2><strong>Accessing data in real-time with the IPC Backbone</strong><a class="headerlink" href="#Accessing-data-in-real-time-with-the-IPC-Backbone" title="Permalink to this headline">¶</a></h2>
<p>If we want to get real-time access to the data generated by Pupil Capture we will need to access the <strong>IPC Backbone</strong>, which is a MessagePack-based API that uses ZeroMQ’s PUB-SUB (publish-subscribe) pattern for one-to-many communication. The IPC Backbone is basically a message relay station that runs as a thread in the main process. To tap into the IPC Backbone we will need both the IP address and the session’s unique port. These can be requested from Pupil Remote as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Request &#39;SUB_PORT&#39; for reading data</span>
<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s1">&#39;SUB_PORT&#39;</span><span class="p">)</span>
<span class="n">sub_port</span> <span class="o">=</span> <span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">()</span>

<span class="c1"># Request &#39;PUB_PORT&#39; for writing data</span>
<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s1">&#39;PUB_PORT&#39;</span><span class="p">)</span>
<span class="n">pub_port</span> <span class="o">=</span> <span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Now, to read data from the IPC Backbone we must <em>subscribe</em> to the <em>topic</em> we are interested in. All messages on the IPC Backbone are multipart messages which contain (at least) two message frames:</p>
<ul class="simple">
<li><p>Frame 1 - contains the topic string (e.g. pupil.1.3d)</p></li>
<li><p>Frame 2 - contains the actual message, which is a msgpack-encoded key-value mapping. Pupil Labs uses msgpack as the serializer due to its efficient format (45% smaller than json, 200% faster than ujson) and because encoders exist for most languages</p></li>
</ul>
<p>Let’s subscribe to the pupil data and receive a single message. Note that here we use msgpack for serialization of the data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">subscriber</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">zmq</span><span class="o">.</span><span class="n">SUB</span><span class="p">)</span>
<span class="n">subscriber</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;tcp://</span><span class="si">{</span><span class="n">address</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">sub_port</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">subscriber</span><span class="o">.</span><span class="n">subscribe</span><span class="p">(</span><span class="s1">&#39;pupil.1.3d&#39;</span><span class="p">)</span>  <span class="c1"># receive all pupil messages</span>

<span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">topic</span><span class="p">,</span> <span class="n">payload</span> <span class="o">=</span> <span class="n">subscriber</span><span class="o">.</span><span class="n">recv_multipart</span><span class="p">()</span>
    <span class="n">message</span> <span class="o">=</span> <span class="n">msgpack</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">message</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
b&#39;pupil.1.3d&#39;: {b&#39;circle_3d&#39;: {b&#39;center&#39;: [-6.062727024239404, 7.2573373425476015, 76.67020568315203], b&#39;normal&#39;: [-0.4862393024567709, -0.179596194083497, -0.8551704788035399], b&#39;radius&#39;: 1.7197839210140726}, b&#39;confidence&#39;: 0.8328064573022729, b&#39;timestamp&#39;: 72800.4434, b&#39;diameter_3d&#39;: 3.4395678420281453, b&#39;ellipse&#39;: {b&#39;center&#39;: [111.09635676517327, 178.74291486962085], b&#39;axes&#39;: [23.059201044972536, 27.97707914059222], b&#39;angle&#39;: 11.253623906156577}, b&#39;location&#39;: [111.09635676517327, 178.74291486962085], b&#39;diameter&#39;: 27.97707914059222, b&#39;sphere&#39;: {b&#39;center&#39;: [-0.22785539475815286, 9.412491671549565, 86.93225142879452], b&#39;radius&#39;: 12.0}, b&#39;projected_sphere&#39;: {b&#39;center&#39;: [158.37493746649633, 187.1298021211465], b&#39;axes&#39;: [171.1677743925462, 171.1677743925462], b&#39;angle&#39;: 90.0}, b&#39;model_confidence&#39;: 0.7356920439193004, b&#39;model_id&#39;: 1, b&#39;model_birth_timestamp&#39;: 72765.503835, b&#39;theta&#39;: 1.390220371094368, b&#39;phi&#39;: -2.0877981403098818, b&#39;norm_pos&#39;: [0.34717611489116645, 0.2552378547099131], b&#39;topic&#39;: b&#39;pupil.1.3d&#39;, b&#39;id&#39;: 1, b&#39;method&#39;: b&#39;3d c++&#39;}
</pre></div></div>
</div>
<p>Here is a more intelligible breakdown of the pupil datum that we just recieved and printed above (from <a class="reference external" href="https://docs.pupil-labs.com/developer/core/overview/#pupil-datum-format">https://docs.pupil-labs.com/developer/core/overview/#pupil-datum-format</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="c1"># pupil datum</span>
    <span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="s1">&#39;pupil.0&#39;</span><span class="p">,</span>
    <span class="s1">&#39;method&#39;</span><span class="p">:</span> <span class="s1">&#39;3d c++&#39;</span><span class="p">,</span>
    <span class="s1">&#39;norm_pos&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>  <span class="c1"># norm space, [0, 1]</span>
    <span class="s1">&#39;diameter&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>  <span class="c1"># 2D image space, unit: pixel</span>
    <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="mf">535741.715303987</span><span class="p">,</span>  <span class="c1"># time, unit: seconds</span>
    <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>  <span class="c1"># [0, 1]</span>

    <span class="c1"># 2D ellipse of the pupil in image coordinates</span>
    <span class="s1">&#39;ellipse&#39;</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># image space, unit: pixel</span>
        <span class="s1">&#39;angle&#39;</span><span class="p">:</span> <span class="mf">90.0</span><span class="p">,</span>  <span class="c1"># unit: degrees</span>
        <span class="s1">&#39;center&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">320.0</span><span class="p">,</span> <span class="mf">240.0</span><span class="p">],</span>
        <span class="s1">&#39;axes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># eye id, 0 or 1</span>

    <span class="c1">## 3D model data</span>
    <span class="c1"># -1 means that the model is building up and has not finished fitting</span>
    <span class="s1">&#39;model_birth_timestamp&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;model_confidence&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s1">&#39;model_id&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>

    <span class="c1"># pupil polar coordinates on 3D eye model. The model assumes a fixed</span>
    <span class="c1"># eye ball size. Therefore there is no `radius` key</span>
    <span class="s1">&#39;theta&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;phi&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>

    <span class="c1"># 3D pupil ellipse</span>
    <span class="s1">&#39;circle_3d&#39;</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># 3D space, unit: mm</span>
        <span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
        <span class="s1">&#39;radius&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s1">&#39;center&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="s1">&#39;diameter_3d&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>  <span class="c1"># 3D space, unit: mm</span>

    <span class="c1"># 3D eye ball sphere</span>
    <span class="s1">&#39;sphere&#39;</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># 3D space, unit: mm</span>
        <span class="s1">&#39;radius&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s1">&#39;center&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="s1">&#39;projected_sphere&#39;</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># image space, unit: pixel</span>
        <span class="s1">&#39;angle&#39;</span><span class="p">:</span> <span class="mf">90.0</span><span class="p">,</span>
        <span class="s1">&#39;center&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="s1">&#39;axes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">},</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The Pupil Core system generates pupil data from eye camera images. It starts by fitting an ellipse to the pupil image and then calculating the diameter of the ellipse in 2d pixel units. This measure, reported as the <strong>diameter</strong> variable, is two-dimensional and therefore sensitive to changes in gaze perspective (e.g. the pupil forshortening error: <a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/25953668/">https://pubmed.ncbi.nlm.nih.gov/25953668/</a>). In addition to the pupil <strong>topic</strong> and the <strong>timestamp</strong> (which get inherited from the eye image), the
fields <strong>norm_pos</strong> and <strong>confidence</strong> are also added. The former is the pupil’s location in normalised eye coordinates and the latter is a value between 0 and 1 indicating the quality of the measurement.</p>
<p>By default, the Pupil Core software uses the 3d detector for pupil detection. This is an extension of the 2d detector, so its data contains keys that were inherited from the 2d detection, as well as new keys specific to the 3d model. Pupil size measurements using the 3d detection mode are valid without correction for perspective, and the best quoted error is 0.01 mm for a pupil with <em>r</em> = 5 mm. Further details on the techspecs can be found here.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://perceptual.mpi-inf.mpg.de/files/2018/04/dierkes18_etra.pdf">https://perceptual.mpi-inf.mpg.de/files/2018/04/dierkes18_etra.pdf</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1405.0006">https://arxiv.org/abs/1405.0006</a></p></li>
</ul>
<p>Section 3.2 of the first paper discusses the 3d eye model and Section 4.3 talks about pupil size estimation. To see the 3-d model in action, open Pupil Capture and go to one of the eye windows. On the “Settings” tab change the mode to “Algorithm”, and then on the “Pupil Detector 3D” tab click “Open Debug Window”. You should see something that looks like this:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="s2">&quot;../../../img/CAPTURE.PNG&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="_images/plr_with_pupil_core_9_0.png" class="no-scaled-link" src="_images/plr_with_pupil_core_9_0.png" style="width: 1000px;" />
</div>
</div>
</div>
<div class="section" id="Annotations-and-notifications">
<h2><strong>Annotations and notifications</strong><a class="headerlink" href="#Annotations-and-notifications" title="Permalink to this headline">¶</a></h2>
<p>To extract our experimental events and calculate time-critical measures of the pupil’s light response (e.g. constriction latency, time-to-peak constriction) we will need a reliable indication in the pupil data of the time at which a light stimulus was actually administered. Pupil Labs has an <strong>Annotation Capture</strong> plugin that can help us with this. The plugin allows timestamps to be marked with a label, which is basically the same as sending ‘messages’ or ‘triggers’. The labels can be created by
pressing customised hotkeys in Pupil Capture or they can be created programmatically and sent to Pupil Capture via the Pupil Core Network API. If our light stimulus could be controlled programmatically and with good timing then we would be able mark the onset and offset of the light within the Pupil recording just by sending an annotation immediately before or after we issue a command to change the status of the light. To do this, we need to start the Annotation Capture plugin, either by
clicking on it in Pupil Capture, or by sending a <strong>notification</strong>. Notifications are special messages that Pupil uses to coordinate activities. They are key-value mappings with a required ‘subject’ field:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">notify</span><span class="o">.&lt;</span><span class="n">notification</span> <span class="n">subject</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># message topic:</span>
<span class="s1">&#39;notify.start_plugin.Annotation_Capture&#39;</span>
<span class="c1"># message payload, a notification dict</span>
<span class="p">{</span><span class="s1">&#39;subject&#39;</span><span class="p">:</span><span class="s1">&#39;recording.start_plugin&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">:</span><span class="s1">&#39;Annotation_Capture&#39;</span><span class="p">}</span>
</pre></div>
</div>
<p>Notifications get passed to all active plugins via the <code class="docutils literal notranslate"><span class="pre">.on_notify()</span></code> callback. To find out which plugins send and receive notifications, open the Pupil codebase and search for <code class="docutils literal notranslate"><span class="pre">.notify_all(</span></code> and <code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">on_notify(</span></code>. Let’s define a function that will send notifications and use it to start the Annotation Capture plugin. The same function will come in handy for general communication with Pupil Capture.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">notify</span><span class="p">(</span><span class="n">pupil_remote</span><span class="p">,</span> <span class="n">notification</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sends ``notification`` to Pupil Remote&quot;&quot;&quot;</span>
    <span class="n">topic</span> <span class="o">=</span> <span class="s2">&quot;notify.&quot;</span> <span class="o">+</span> <span class="n">notification</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">msgpack</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">notification</span><span class="p">,</span> <span class="n">use_bin_type</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">zmq</span><span class="o">.</span><span class="n">SNDMORE</span><span class="p">)</span>
    <span class="n">pupil_remote</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">()</span>

<span class="c1"># start the Annotation Capture plugin</span>
<span class="n">notify</span><span class="p">(</span><span class="n">pupil_remote</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;subject&quot;</span><span class="p">:</span> <span class="s2">&quot;start_plugin&quot;</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Annotation_Capture&quot;</span><span class="p">,</span> <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{}})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;Message forwarded.&#39;
</pre></div></div>
</div>
<p>Now we just need functions to create and send the annotations / triggers / event markers / whatever we want to call them.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">send_trigger</span><span class="p">(</span><span class="n">trigger</span><span class="p">):</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">msgpack</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">trigger</span><span class="p">,</span> <span class="n">use_bin_type</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">pub_socket</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="n">trigger</span><span class="p">[</span><span class="s2">&quot;topic&quot;</span><span class="p">],</span> <span class="n">flags</span><span class="o">=</span><span class="n">zmq</span><span class="o">.</span><span class="n">SNDMORE</span><span class="p">)</span>
    <span class="n">pub_socket</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">new_trigger</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">duration</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;annotation&quot;</span><span class="p">,</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span>
        <span class="s2">&quot;timestamp&quot;</span><span class="p">:</span> <span class="n">time</span><span class="p">(),</span>
        <span class="s2">&quot;duration&quot;</span><span class="p">:</span> <span class="n">duration</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
<p>Now, using the functions defined above, let’s do a short recording where we send 10 messages a couple of seconds apart. Note that, before starting recording, we need to set Pupil Capture’s time to the time of this script. This example is based on a more complete example here: <a class="reference external" href="https://github.com/pupil-labs/pupil-helpers/blob/master/python/remote_annotations.py">https://github.com/pupil-labs/pupil-helpers/blob/master/python/remote_annotations.py</a></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pub_socket</span> <span class="o">=</span> <span class="n">zmq</span><span class="o">.</span><span class="n">Socket</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">zmq</span><span class="o">.</span><span class="n">PUB</span><span class="p">)</span>
<span class="n">pub_socket</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;tcp://</span><span class="si">{}</span><span class="s2">:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">address</span><span class="p">,</span> <span class="n">pub_port</span><span class="p">))</span>

<span class="c1"># set Pupil Capture&#39;s time base to the same time as this script (should be done before starting the recording)</span>
<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s2">&quot;T </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">())</span>

<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s1">&#39;R our_recording&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">())</span>

<span class="n">our_events</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">trigger</span> <span class="o">=</span> <span class="n">new_trigger</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;our_event&#39;</span><span class="p">,</span> <span class="n">duration</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">send_trigger</span><span class="p">(</span><span class="n">trigger</span><span class="p">)</span>
    <span class="n">our_events</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Our event at: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">our_events</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">())</span>

<span class="n">our_events</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">our_events</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Timesync successful.
OK
Our event at: 1592300706.7236795
Our event at: 1592300708.7239833
Our event at: 1592300710.7252498
Our event at: 1592300712.7253377
Our event at: 1592300714.7269917
Our event at: 1592300716.7287822
Our event at: 1592300718.7298121
Our event at: 1592300720.7302544
Our event at: 1592300722.7311578
Our event at: 1592300724.7323549
OK
</pre></div></div>
</div>
<p>If we now find this recording and drop it into Pupil Player, making sure the <strong>Annotation Player</strong> plugin is active, the software will print the messages to the screen during playback. And if we export the data (press ‘e’ or click export button) we will have a .csv file containing our annotations.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">annotations</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;C:\Users\engs2242\recordings\our_recording\051\exports\000\annotations.csv&quot;</span><span class="p">)</span>
<span class="n">annotations</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>timestamp</th>
      <th>label</th>
      <th>duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>192</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>391</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>589</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>788</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>987</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1186</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1385</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1584</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1783</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1980</td>
      <td>1.592301e+09</td>
      <td>our_event</td>
      <td>0.1</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Now we can check the timing difference between the annotation timestamps and our_events.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">our_events</span> <span class="o">-</span> <span class="n">annotations</span><span class="p">[</span><span class="s2">&quot;timestamp&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0    0.000000e+00
1    0.000000e+00
2    0.000000e+00
3    2.384186e-07
4    2.384186e-07
5    0.000000e+00
6    2.384186e-07
7    0.000000e+00
8    0.000000e+00
9    2.384186e-07
dtype: float64
</pre></div></div>
</div>
<p>Looks good inititally, but probably worth doing a more thorough test at some point.</p>
</div>
<div class="section" id="Using-the-World-Camera-to-detect-light-onset">
<h2><strong>Using the World Camera to detect light onset</strong><a class="headerlink" href="#Using-the-World-Camera-to-detect-light-onset" title="Permalink to this headline">¶</a></h2>
<p>The process outlined above looks to be reliable and efficient but it assumes no latency on the part of the actual event (e.g. a pulse of light). In our case, we can use the STLAB in asynchronous mode (i.e. with a video file) to precisely control the <em>duration</em> of a light stimulus, but we know that the command to start playing the video file will take some time to process. Usually this ranges between 100-200 ms, but it can sometimes be as high as 5 s due to various factors such as hardware,
processes, whatever the LIGHT HUB is doing at the time, etc. This means that it will not suffice to simply send an annotation before / after we call <code class="docutils literal notranslate"><span class="pre">stlab.Device.play_video_file(...)</span></code>, as the timestamp will not be a reliable indication of light onset. To extract our events and calculate accurate pupil constriction latencies, which are typically on the order of around 200-250 ms, we will need an efficient means of time-stamping stimulus onset. One possibility is to use the WorldCam to detect
the onset of the light stimulus and its associated timestamp. For this, we’ll need to use the <strong>Network APIs Frame Publisher</strong>, making sure that the format is set to <strong>bgr</strong>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#notify({&quot;subject&quot;:&quot;start_plugin&quot;,&quot;name&quot;:&quot;UVC_Source&quot;,&quot;args&quot;:{&quot;exposure_mode&quot;:&quot;manual&quot;,&quot;frame_size&quot;: (640, 480),&quot;frame_rate&quot;: 60,&quot;name&quot;:&quot;Pupil Cam1 ID2&quot;}})</span>
<span class="c1">#notify({&quot;subject&quot;:&quot;start_plugin&quot;,&quot;name&quot;:&quot;UVC_Source&quot;,&quot;args&quot;:{&quot;frame_size&quot;: (640, 480),&quot;frame_rate&quot;: 60,&quot;name&quot;:&quot;Pupil Cam1 ID2&quot;,&quot;exposure_mode&quot;:&quot;manual&quot;}})</span>
<span class="n">notify</span><span class="p">({</span><span class="s2">&quot;subject&quot;</span><span class="p">:</span><span class="s2">&quot;frame_publishing.set_format&quot;</span><span class="p">,</span> <span class="s2">&quot;format&quot;</span><span class="p">:</span><span class="s2">&quot;bgr&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;Message forwarded.&#39;
</pre></div></div>
</div>
<p>This Frame Publisher publishes WorldCam data in various formats under the topic frame.world. The code above starts the plugin in <strong>bgr</strong> format. Now we need a function that can receive the data in real time, and another function that can poll the world camera for a sudden increase in luminance and send an annotation with the associated timestamp. The ideas for these functions come from here: <a class="reference external" href="https://github.com/pupil-labs/pupil-helpers/blob/master/python/recv_world_video_frames.py">https://github.com/pupil-labs/pupil-helpers/blob/master/python/recv_world_video_frames.py</a></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">recv_from_sub</span><span class="p">():</span>
    <span class="sd">&#39;&#39;&#39;Recv a message with topic, payload.</span>
<span class="sd">    Topic is a utf-8 encoded string. Returned as unicode object.</span>
<span class="sd">    Payload is a msgpack serialized dict. Returned as a python dict.</span>
<span class="sd">    Any addional message frames will be added as a list</span>
<span class="sd">    in the payload dict with key: &#39;__raw_data__&#39; .</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">topic</span> <span class="o">=</span> <span class="n">sub</span><span class="o">.</span><span class="n">recv_string</span><span class="p">()</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">msgpack</span><span class="o">.</span><span class="n">unpackb</span><span class="p">(</span><span class="n">sub</span><span class="o">.</span><span class="n">recv</span><span class="p">(),</span> <span class="n">raw</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">extra_frames</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="n">sub</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">zmq</span><span class="o">.</span><span class="n">RCVMORE</span><span class="p">):</span>
        <span class="n">extra_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sub</span><span class="o">.</span><span class="n">recv</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">extra_frames</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;__raw_data__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">extra_frames</span>
    <span class="k">return</span> <span class="n">topic</span><span class="p">,</span> <span class="n">payload</span>

<span class="k">def</span> <span class="nf">detect_light_onset</span><span class="p">(</span><span class="n">trigger</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="n">recent_world</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">recent_world_m1</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">recent_world_ts</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">detected</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Waiting for the light...&quot;</span><span class="p">)</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">detected</span><span class="p">:</span>
        <span class="n">topic</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">recv_from_sub</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">topic</span> <span class="o">==</span> <span class="s1">&#39;frame.world&#39;</span><span class="p">:</span>
            <span class="n">recent_world</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">msg</span><span class="p">[</span><span class="s1">&#39;__raw_data__&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">msg</span><span class="p">[</span><span class="s1">&#39;height&#39;</span><span class="p">],</span> <span class="n">msg</span><span class="p">[</span><span class="s1">&#39;width&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
            <span class="n">recent_world_ts</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">recent_world</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">recent_world_m1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">recent_world</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">recent_world_m1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">diff</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Light change detected at </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recent_world_ts</span><span class="p">))</span>
                <span class="n">trigger</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">recent_world_ts</span> <span class="c1"># change timestamp</span>
                <span class="n">send_trigger</span><span class="p">(</span><span class="n">trigger</span><span class="p">)</span>
                <span class="n">detected</span><span class="o">=</span><span class="kc">True</span>
                <span class="k">break</span>
        <span class="n">recent_world_m1</span> <span class="o">=</span> <span class="n">recent_world</span>
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">detect_light_onset(...)</span></code> function will basically grab and unpack data from the world camera, reshape it in a numpy array with the correct resolution, calculate the mean, compare it to the mean of the previous frame, and then send a timestamped message using the Pupil timestamp associated with the first frame where the difference exceeds a given threshold. For this to work, <strong>Auto Exposure Mode</strong> for Video source in Pupil Capture must be set to <strong>manual mode</strong>, and it is probably best to
disable the <strong>Auto Exposure Priority</strong> and play around with the <strong>Absolute Exposure Time</strong> to see what works best. Let’s try it out. Make sure the lighting in the room is constant and have a light source at hand (e.g. smart phone torch, light switch). It might be necessary to adjust the threshold to suit the environment / camera settings. Also, for this application, as we are only detecting a change in brightness we can use a lower resolution and take advantage of the faster frame rate that this
allows (e.g. set resolution to [640, 480] and frame rate to 120). Note that 1) we are waiting on data from Pupil Labs to figure out if this will actually help… 2) if the light source is to be controlled programatically, <code class="docutils literal notranslate"><span class="pre">detect_light_onset(...)</span></code> will probably need to run in its own thread.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pub_socket</span> <span class="o">=</span> <span class="n">zmq</span><span class="o">.</span><span class="n">Socket</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">zmq</span><span class="o">.</span><span class="n">PUB</span><span class="p">)</span>
<span class="n">pub_socket</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;tcp://</span><span class="si">{}</span><span class="s2">:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">address</span><span class="p">,</span> <span class="n">pub_port</span><span class="p">))</span>

<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s2">&quot;T </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">())</span>

<span class="n">sub</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">zmq</span><span class="o">.</span><span class="n">SUB</span><span class="p">)</span>
<span class="n">sub</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;tcp://</span><span class="si">{}</span><span class="s2">:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">address</span><span class="p">,</span> <span class="n">sub_port</span><span class="p">))</span>

<span class="c1"># set subscriptions to topics</span>
<span class="c1"># recv just pupil/gaze/notifications</span>
<span class="n">sub</span><span class="o">.</span><span class="n">setsockopt_string</span><span class="p">(</span><span class="n">zmq</span><span class="o">.</span><span class="n">SUBSCRIBE</span><span class="p">,</span> <span class="s1">&#39;frame.&#39;</span><span class="p">)</span>

<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s2">&quot;R&quot;</span><span class="p">)</span>
<span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">()</span>

<span class="n">sleep</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span>

<span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;LIGHT_ON&quot;</span>
<span class="n">light_on_trigger</span> <span class="o">=</span> <span class="n">new_trigger</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">detect_light_onset</span><span class="p">(</span><span class="n">light_on_trigger</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">pupil_remote</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">pupil_remote</span><span class="o">.</span><span class="n">recv_string</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Timesync successful.
Waiting for the light...
Light change detected at 1592301090.6281967
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;OK&#39;
</pre></div></div>
</div>
<p>Now load this recording into Pupil Player and make sure the Annotation Player plugin is active. Play back the video, and hopefully the LIGHT_ON annotation is stamped on the screen where the light appeared. This means we can use this annotation and its associated timestamp to extract the data for our PLR (see below for notes on latency / variability). It will take some optimisation, but this principle can be used to detect the onset of a light stimulus administered by the STLAB. Another neat
thing about this approach is that it doesn’t require an integrating sphere and an expensive light engine to work – anyone with a Pupil Core device could measure their PLR using only a light switch in and a dark room.</p>
</div>
<div class="section" id="Notes-on-latency">
<h2><strong>Notes on latency</strong><a class="headerlink" href="#Notes-on-latency" title="Permalink to this headline">¶</a></h2>
<p>The following notes on latency are from communications with Pupil Labs on Discord:</p>
<p>“<em>We differentiate between hardware timestamps and software timestamps. Hardware timestamps are generated by the camera at the start of the frame exposure. The software timestamps are generated by pyuvc using the system’s monotonic clock at the time when the frame has finished transferring from the camera to the computer. The difference between the software and hardware timestamps is what we call camera latency. Camera latency is dependent on frame resolution, as a higher frame resolution
requires more data to be transferred from the camera to the computer.</em></p>
<p><em>Ideally, we would use hardware timestamps at all times. Unfortunately, we have noticed that the camera and system clocks are not necessarily synchronized at all times and on all OS. Especially on Windows, we have seen major discrepancies. This is very problematic, as every of the three cameras is using its own clock, and if they are not synchronized, pupil data cannot be matched and mapped to gaze properly.</em></p>
<p><em>This is why we use corrected software timestamps instead. These are software timestamps from which we subtract a fixed amount of time to compensate the camera latency approximately.</em></p>
<p><em>In summary, the recorded timestamps should correspond to the actual time at which the frame was recorded. Therefore, the relevant questions are (1) how accurate the camera latency is approximated and (2) how much it varies. (Unfortunately, I cannot give representative values for this at the time as we were not able to measure the actual camera delay on Windows due to the desynchronized clocks.) Processing latency and camera frame rate do not play a role at all in this context as they do not
affect hardware nor software timestamps.</em>”</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">PyPlr</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="overview.html">Overview</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="overview.html#hardware-interfacing">Hardware interfacing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Example Protocols</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="developers.html">Developers</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgements.html">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="todo.html">To Do…</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="overview.html">Overview</a><ul>
      <li>Previous: <a href="overview.html" title="previous chapter">Overview</a></li>
      <li>Next: <a href="STLAB_introduction.html" title="next chapter"><strong>Introduction to the STLAB light engine</strong></a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Joel T. Martin and Manuel Spitschan.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.4.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/plr_with_pupil_core.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>