# -*- coding: utf-8 -*-
'''
Created on Mon Mar 30 17:05:47 2020
@author: JTM
note: credit to Acland BT, Braver TS (2014) for some of this code
https://github.com/beOn/cili
Acland BT, Braver TS (2014). Cili (v0.5.4) [Software] 
Available from http://doi.org/10.5281/zenodo.48843. doi:10.5281/zenodo.48843
'''

import os
import shutil
import os.path as op
from copy import deepcopy

import numpy as np
import pandas as pd

##########################
# FUNCTIONS TO LOAD DATA #
##########################

def init_subject_analysis(subjdir, out_dir_nm='pyplr_analysis'):
    '''
    Initiate data analysis for a given subject.
    
    Parameters
    ----------
    subjdir : str
        Path to subject directory
    out_dir_nm : str, optional
        Name for the new directory where analysis results will be saved. 
        The default is 'pyplr_analysis'.
    Returns
    -------
    dict
        information for the subject.
        
    '''
    subjid = op.basename(subjdir[:-1])
    print('{}\n{:*^60s}\n{}'.format('*' * 60, subjid, '*' * 60,))
    pl_data_dir = op.join(subjdir, 'exports', '', '000', '') # default for data exported from pupil player
    out_dir = op.join(subjdir, out_dir_nm, '')
    if os.path.exists(out_dir):
        shutil.rmtree(out_dir)
    os.mkdir(out_dir)
    
    return {
        'id':subjid,
        'root':subjdir,
        'pl_data_dir':pl_data_dir, 
        'out_dir':out_dir
        }

def load_annotations(data_dir):
    '''
    Loads annotations (a.k.a. 'triggers', 'events', etc.) exported 
    from Pupil Player.
    
    Parameters
    ----------
    data_dir : str
        Directory where the Pupil Labs 'annotations' data exists.
    Returns
    -------
    events : DataFrame
        Pandas DataFrame containing events.
        
    '''
    fname = op.join(data_dir, '', 'annotations.csv')
    try:
        events = pd.read_csv(fname)
        print('Loaded {} events'.format(len(events)))
    except FileNotFoundError:
        print('{} does not appear to exist. Make sure annotations plugin is \
              active before exporting'.format(fname))
        
    return events
   
def load_pupil(data_dir, method='3d c++', cols=[]):
    '''
    Loads 'pupil_positions' data exported from Pupil Player.
    
    Parameters
    ----------
    data_dir : str
        Directory where the Pupil Labs 'annotations' data exists.
    method : string
        Whether to load pupil data generated by the 2d or 3d fitting method. 
        The default is '3d c++'.
    cols : list
        Columns to load from the file, e.g. ['pupil_timestamp','diameter','diameter_3d']
        (check file for options). The default is [] (loads all columns).
    Returns
    -------
    samps : DataFrame
        Pandas DataFrame containing requested samples.
        
    '''
    fname = op.join(data_dir, '', 'pupil_positions.csv')
    try:
        if not cols:
            samps = pd.read_csv(fname)
        else:
            samps = pd.read_csv(fname, usecols=cols)
        samps = samps[samps.method==method]    
        samps.set_index('pupil_timestamp', inplace=True)
        print('Loaded {} samples'.format(len(samps)))
        print('Average confidence: {}'.format(samps.confidence.mean()))
    except FileNotFoundError:
        print('{} does not appear to exist. Check directory and pupil player'.format(fname))
    
    return samps

def load_blinks(data_dir):
    '''
    Loads 'blinks' data exported from Pupil Player.
    
    Parameters
    ----------
    data_dir : str
        Directory where the Pupil Labs 'blinks' data exists.
    Returns
    -------
    blinks : DataFrame
        Pandas DataFrame containing blink events.
        
    '''
    fname = op.join(data_dir, '', 'blinks.csv')
    try:
        blinks = pd.read_csv(fname)
        print('{} blinks detected by Pupil Labs, average duration {:.3f} s'.format(
            len(blinks), blinks.duration.mean()))
    except FileNotFoundError:
        print('{} does not appear to exist. Make sure blink detection plugin is \
              active before exporting in Pupil Player'.format(fname))
    return blinks

###########################
# FUNCTIONS TO CLEAN DATA #
###########################
    
def confidence_filter(samples, threshold=.8, mask_cols=['diameter']):
    '''
    Sets data in mask_cols to NaN where the corresponding confidence metric is
    below threshold. Pupil Labs reccommend a threshold of .8. An alterntive
    to interpolating blinks. 

    Parameters
    ----------
    samples : DataFrame
        The samples from which to pull indices.
    threshold : float, optional
        Threshold to use for filtering by confidence. The default is .8.
    mask_cols : list, optional
        Columns to mask. The default is ['diameter'].

    Returns
    -------
    samps : DataFrame
        masked data
        
    '''
    
    return 1
    

def ev_row_idxs(samples, blinks):
    ''' 
    Returns the indices in 'samples' contained in events from 'events'.
    
    Parameters
    ----------
    samples : DataFrame
        The samples from which to pull indices.
    events : DataFrame
        The events whose indices should be pulled from 'samples'.
        
    Returns
    -------
    samps : DataFrame
        masked data
        
    '''
    idxs = []
    for start, end in zip(blinks['start_timestamp'],blinks['end_timestamp']):
        idxs.extend(list(samples.loc[start:end].index))
    idxs = np.unique(idxs)
    idxs = np.intersect1d(idxs, samples.index.tolist())
    return idxs

def get_mask_idxs(samples, blinks):
    '''
    Finds indices from 'samples' within the returned events.
    
    '''
    blidxs = ev_row_idxs(samples, blinks)
    return blidxs

def mask_blinks(samples, blinks, mask_cols=['diameter']):
    '''
    Sets untrustworthy pupil data to NaN.
    
    Parameters
    ----------
    samples : DataFrame
        Must contain at least 'pupil_timestamp' and 'diameter' columns
    blinks : DataFrame
        Must contain 'start_timestamp' and 'end_timestamp' columns
    mask_cols : list, optional
        Columns to mask. The default is ['diameter'].
    Returns
    -------
    samps : DataFrame
        masked data
        
    '''
    samps = samples.copy(deep=True)
    indices = get_mask_idxs(samps, blinks)
    samps.loc[indices, mask_cols] = float('nan')
    samps['interpolated'] = 0
    samps.loc[indices, 'interpolated'] = 1
    return samps

def interpolate_blinks(samples, blinks, fields=['diameter']):
    '''
    Reconstructs Pupil Labs eye blinks with linear interpolation.
    
    Parameters
    ----------
    samples : DataFrame
        Must contain at least 'pupil_timestamp' and 'diameter' columns
    blinks : DataFrame
        Must contain 'start_timestamp' and 'end_timestamp' columns
    interp_cols : list, optional
        Columns to interpolate. The default is ['diameter'].
        
    Returns
    -------
    samps : DataFrame
        blink-interpolated data
        
    '''
    samps = mask_blinks(samples, blinks, mask_cols=fields)
    samps = samps.interpolate(method='linear', axis=0, inplace=False)
    
    print('{} samples ({:.3f} %) reconstructed with linear interpolation'.format(
        len(samps.loc[samps['interpolated']==1]), 
        samps.loc[:, 'interpolated'].value_counts(normalize=True)[1] * 100))
    return samps

def mask_zeros(samples, mask_cols=['diameter']):
    ''' 
    Sets any 0 values in columns in mask_cols to NaN.
    
    Parameters
    ----------
    samples : DataFrame
        The samples to search for 0 values.
    mask_fields (list of strings)
        The columns to search for 0 values.
        
    '''
    samps = samples.copy(deep=True)
    for f in mask_cols:
        samps[samps[f] == 0] = float('nan')
    return samps

def interpolate_zeros(samples, fields=['diameter']):
    ''' 
    Replace 0s in "samples" with linearly interpolated data.
    Parameters
    ----------
    samples : DataFrame
        The samples in which you'd like to replace 0s
    interp_cols : list
        The column names from samples in which you'd like to replace 0s.
    '''
    samps = mask_zeros(samples, mask_cols=fields)
    samps = samps.interpolate(method='linear', axis=0, inplace=False)
    # since interpolate doesn't handle the start/finish, bfill the ffill to
    # take care of NaN's at the start/finish samps.
    samps.fillna(method='bfill', inplace=True)
    samps.fillna(method='ffill', inplace=True)
    return samps  

def butterworth_series(samples,
                       fields=['diameter'], 
                       filt_order=3,
                       cutoff_freq=.01,
                       inplace=False):
    '''
    Applies a butterworth filter to the given fields
    See documentation on scipy's butter method FMI.
    '''
    import scipy.signal as signal
    samps = samples if inplace else samples.copy(deep=True)
    B, A = signal.butter(filt_order, cutoff_freq, output='BA')
    samps[fields] = samps[fields].apply(
        lambda x: signal.filtfilt(B, A, x), axis=0)
    return samps

def savgol_series(samples, 
                  fields=['diameter'], 
                  window_length=51, 
                  filt_order=7,
                  inplace=False): 
    '''
    Applies a savitsky-golay filter to the given fields
    See documentation on scipys savgol_filter method FMI.
    '''
    import scipy.signal as signal
    samps = samples if inplace else samples.copy(deep=True)
    samps[fields] = samps[fields].apply(
        lambda x: signal.savgol_filter(x, window_length, filt_order), axis=0)
    return samps
    
###########
# extract #
###########
    
def extract(samples, 
            events, 
            offset=0, 
            duration=0,
            borrow_attributes=[]):
    '''
    Extracts ranges from samples based on event timing and sample count.
    Parameters
    ----------
    samples : DataFrame
        The samples from which to extract events. Index must be timestamp.
    events : DataFrame
        The events to extract. Index must be timestamp.
    offset : int, optional
        Number of samples to offset from baseline. The default is 0.
    duration : int, optional
        Duration of all events in terms of the number of samples. Currently 
        this has to be the same for all events, but could use a 'duration' 
        column in events DataFrame if needs be. The default is 0.
    borrow_attributes : list of str, optional
        List of column names in the events DataFrame whose values should be
        copied to the respective ranges. For each item in the list, a
        column will be created in the ranges dataframe - if the column does
        not exist in the events dataframe, the values in the each
        corresponding range will be set to float('nan'). This is uesful for 
        marking conditions, grouping variables, etc. The default is [].
        
    Returns
    -------
    df : DataFrame
        Extracted events complete with hierarchical multi-index.
        
    '''
    # negative duration should raise an exception
    if duration <= 0:
        raise ValueError('Duration must be >0')
        
    # get the list of start time indices
    e_starts = events.index.to_series()

    # find the indexes of the event starts, and offset by sample count
    r_idxs = np.searchsorted(samples.index, e_starts.iloc[:], 'left') + offset
    r_dur = duration

    # make a hierarchical index
    samples['orig_idx'] = samples.index
    midx = pd.MultiIndex.from_product(
        [list(range(len(e_starts))), list(range(r_dur))],
        names=['event', 'onset'])
    
    # get the samples
    df = pd.DataFrame()
    idx = 0
    for s_idx in r_idxs:
        # get the start time and add the required number of indices
        e_idx = s_idx + r_dur - 1  # pandas.loc indexing is inclusive
        # deepcopy for old bugs
        new_df = deepcopy(
            samples.loc[samples.index[s_idx]: samples.index[e_idx]])
        for ba in borrow_attributes:
            new_df[ba] = events.iloc[idx].get(ba, float('nan'))
        df = pd.concat([df, new_df])
        idx += 1
    df.index = midx
    
    print('Extracted ranges for {} events'.format(len(events)))
    return df

def reject_bad_trials(ranges, interp_thresh=20, drop=False):
    '''
    Drop or markup trials which exceed a threshold of interpolated data.
    
    Parameters
    ----------
    ranges : DataFrame
        Extracted event ranges with hierarchical pd.MultiIndex.
    interp_thresh : int, optional
        Percentage of interpolated data permitted before trials are marked for
        rejection / dropped. The default is 20.
    drop : bool, optional
        Whether to drop the trials from the ranges. The default is False.
        
    Returns
    -------
    ranges : DataFrame
        Same as ranges but with a column identifying trials marked for
        rejection (drop = False) or with those trials dropped from the 
        DataFrame (drop = True).
        
    '''
    if not isinstance(ranges.index, pd.MultiIndex):
        raise ValueError('Index of ranges must be pd.MultiIndex')
        
    pct_interp = ranges.groupby(by='event').agg(
        {'interpolated':lambda x: float(x.sum())/len(x)*100})
    print('Percentage of data interpolated for each trial (mean = {:.2f}): \n'.format(
        pct_interp.mean()[0]), pct_interp)
    reject_idxs = pct_interp.loc[pct_interp['interpolated'] > interp_thresh].index.to_list()
    ranges['reject'] = 0
    if reject_idxs:
        ranges.loc[reject_idxs, 'reject'] = 1
    if drop:
        ranges = ranges.drop(index=reject_idxs)
        print('{} trials were dropped from the DataFrame'.format(len(reject_idxs)))
    else:
        print('{} trials were marked for rejection'.format(len(reject_idxs)))
    return ranges
